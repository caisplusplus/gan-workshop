{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# All the necesssary imports.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Activation, Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the data.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Normalize to [-1, 1] (easier to work with)\n",
    "x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "# For the sake of time don't work with the entire dataset.\n",
    "x_train = x_train[:10000]\n",
    "y_train = x_train[:10000]\n",
    "\n",
    "# Flatten the data.\n",
    "x_train = x_train.reshape((-1, 784))\n",
    "x_test = x_test.reshape((-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ed1f098e492e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot out a sample image (reshaped to 28 x 28)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot out a sample image (reshaped to 28 x 28)\n",
    "plt.imshow(x_train[0].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many noise dimensions our generator should take in\n",
    "NOISE_DIM = 100 # Feel free to tweak this and see what changes\n",
    "\n",
    "def generator():\n",
    "    ###################################\n",
    "    #TODO: Implement\n",
    "    \n",
    "    ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    ###################################\n",
    "    #TODO: Implement\n",
    "    \n",
    "    ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine(generator, discriminator):\n",
    "    ###################################\n",
    "    # TODO: Implement\n",
    "    model = Sequential()\n",
    "    return model\n",
    "    ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the discriminator, generator, and full GAN. \n",
    "\n",
    "# Use this optimizer for each of the models\n",
    "opt = Adam(lr=.0002, beta_1=0.5)\n",
    "\n",
    "#############################################\n",
    "# TODO: Compile generator and discriminator\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to display sample from the network\n",
    "def disp_sample(g):\n",
    "    noise = np.random.uniform(-1, 1, size=(batch_size, NOISE_DIM))\n",
    "    generated_images = g.predict(noise, verbose=0)\n",
    "    show_im = generated_images[0]\n",
    "    show_im = (show_im + 1) / 2.0\n",
    "    show_im = show_im.reshape(28, 28)\n",
    "    plt.imshow(show_im, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "for epoch in range(100):\n",
    "    print('Epoch #%d' % epoch)\n",
    "    \n",
    "    # Generate an image and display it.\n",
    "    disp_sample(g)\n",
    "    \n",
    "    num_batches = int(x_train.shape[0] / batch_size)\n",
    "    print('Number batches %i' % num_batches)\n",
    "    for i in range(num_batches):\n",
    "        # A training iteration\n",
    "        \n",
    "        # Generate noise.\n",
    "        noise = np.random.uniform(-1, 1, size=(batch_size, NOISE_DIM))\n",
    "        \n",
    "        # Generate images from the noise using the generator.\n",
    "        generated_images = g.predict(noise)\n",
    "        \n",
    "        # Grab the image batch for this iteration. \n",
    "        real_images = x_train[i * batch_size: (i+1) * batch_size]\n",
    "        \n",
    "        # Contains the real and fake images.\n",
    "        X = np.concatenate([generated_images, real_images])\n",
    "        \n",
    "        # Labels if the sample is real (1) or not real (0). \n",
    "        y = np.concatenate([np.zeros(generated_images.shape[0]), np.ones(real_images.shape[0])])\n",
    "\n",
    "        # Train the discriminator using the generated images and the real images.\n",
    "        d.trainable = True\n",
    "        d_loss = d.train_on_batch(X, y)\n",
    "        d.trainable = False\n",
    "        \n",
    "        # Generate more noise to feed into the full gan network to train the generative portion. \n",
    "        noise = np.random.uniform(-1, 1, size=(batch_size, NOISE_DIM))\n",
    "\n",
    "        # Get the g_loss\n",
    "        g_loss = gd.train_on_batch(noise, np.ones(noise.shape[0]))\n",
    "        \n",
    "        print('%i(%i/%i) D: %.4f, G: %.4f' % (epoch, i, num_batches, d_loss, g_loss))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
